# ==============================================================================
# Part 1: Configuration - Default Weights and Scoring Maps
# ==============================================================================

import logging
import json

# Configure logging for scorer
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('scorer')

# This dictionary represents the standard weights if the user provides none.
# The values represent the importance of each category on a relative scale.
DEFAULT_WEIGHTS = {
    "materials": 3,
    "durability": 3,
    "logistics": 2,
    "packaging": 1,
    "certifications": 4,
}

# These maps convert the LLM's text analysis into normalized numerical values.
# The scale is from -1.0 (very bad) to 1.0 (very good).
MATERIAL_SCORES = {
    'Recycled': 1.0,
    'Natural': 0.8,
    'Wood': 0.8,
    'Synthetic (Recycled)': 0.6,
    'Metal': 0.2,
    'Mixed': -0.4,
    'Synthetic': -0.8,
    'Unknown': 0.0,
}
DURABILITY_SCORES = {'High': 1.0, 'Medium': 0.5, 'Low': -1.0, 'Unknown': 0.0}
LOGISTICS_SCORES = {'Local': 1.0, 'Regional': 0.3, 'International': -0.8, 'Unknown': 0.0}
PACKAGING_SCORES = {'Eco-friendly': 1.0, 'Plastic-free': 0.8, 'Standard': 0.0, 'Not Mentioned': 0.0}


# ==============================================================================
# Part 2: Function to Generate the Sustainability Breakdown
# ==============================================================================

def generate_sustainability_breakdown(analysis_json: dict) -> dict:
    """
    Translates the text-based LLM analysis into a rich breakdown object.

    This object contains both the qualitative value (e.g., "Medium") and the
    quantitative score (e.g., 0.5) for each component, making it perfect for
    both display and calculation.

    Args:
        analysis_json: The full, structured JSON object from the LLM in analyzer.py.

    Returns:
        A dictionary containing the detailed sustainability breakdown.
    """
    logger.info("=== SCORER: GENERATING SUSTAINABILITY BREAKDOWN ===")
    logger.info(f"Input analysis_json: {json.dumps(analysis_json, indent=2)}")
    
    breakdown = {}
    
    # --- Materials Breakdown ---
    logger.info("Processing materials breakdown...")
    material_type = analysis_json.get('materials', {}).get('type', 'Unknown')
    material_score = MATERIAL_SCORES.get(material_type, 0.0)
    breakdown['materials'] = {
        "value": material_type,
        "score": material_score
    }
    logger.info(f"Materials: {material_type} -> score: {material_score}")
    
    # --- Durability Breakdown ---
    logger.info("Processing durability breakdown...")
    durability_assessment = analysis_json.get('durability_and_longevity', {}).get('assessment', 'Unknown')
    durability_score = DURABILITY_SCORES.get(durability_assessment, 0.0)
    breakdown['durability'] = {
        "value": durability_assessment,
        "score": durability_score
    }
    logger.info(f"Durability: {durability_assessment} -> score: {durability_score}")
    
    # --- Logistics Breakdown ---
    logger.info("Processing logistics breakdown...")
    distance_implication = analysis_json.get('logistics_and_shipping', {}).get('shipping_distance_implication', 'Unknown')
    logistics_score = LOGISTICS_SCORES.get(distance_implication, 0.0)
    breakdown['logistics'] = {
        "value": distance_implication,
        "score": logistics_score
    }
    logger.info(f"Logistics: {distance_implication} -> score: {logistics_score}")

    # --- Packaging Breakdown ---
    logger.info("Processing packaging breakdown...")
    packaging_desc = analysis_json.get('packaging', {}).get('description', 'Not Mentioned')
    packaging_value = 'Not Mentioned'
    if 'plastic-free' in packaging_desc.lower() or 'eco-friendly' in packaging_desc.lower():
        packaging_value = 'Eco-friendly'
    breakdown['packaging'] = {
        "value": packaging_value,
        "score": PACKAGING_SCORES.get(packaging_value, 0.0)
    }

    # --- Certifications Breakdown ---
    cert_list = analysis_json.get('certifications', {}).get('list', [])
    cert_count = len(cert_list)
    cert_value = f"{cert_count} Claim(s)" if cert_count > 0 else "None"
    breakdown['certifications'] = {
        "value": cert_value,
        "score": min(1.0, cert_count * 0.5) # 0.5 points per cert, max of 1.0
    }

    return breakdown


# ==============================================================================
# Part 3: Function to Calculate the Final Weighted Score
# ==============================================================================

def calculate_weighted_score(sustainability_breakdown: dict, user_weights: dict | None = None) -> int:
    """
    Calculates the final 0-100 score from the breakdown object and weights.
    This function is extremely fast as it only does mathematical operations.

    Args:
        sustainability_breakdown: The object generated by generate_sustainability_breakdown().
        user_weights: The user's personalized weights. If None, uses default weights.

    Returns:
        The final sustainability score, an integer between 0 and 100.
    """
    logger.info("=== SCORER: CALCULATING WEIGHTED SCORE ===")
    logger.info(f"Sustainability breakdown: {json.dumps(sustainability_breakdown, indent=2)}")
    logger.info(f"User weights: {user_weights}")
    
    # Use user-provided weights, or fall back to the defaults
    weights = user_weights or DEFAULT_WEIGHTS
    logger.info(f"Using weights: {weights}")
    
    total_weighted_score = 0
    total_weight = 0
    
    logger.info("Processing each category...")
    # Iterate through the breakdown object to calculate the total score
    for category, breakdown_details in sustainability_breakdown.items():
        # Get the normalized score (-1.0 to 1.0) for the category
        score = breakdown_details.get('score', 0.0)
        # Get the user's weight for that category
        weight = weights.get(category, 0)
        
        weighted_contribution = score * weight
        total_weighted_score += weighted_contribution
        total_weight += weight
        
        logger.info(f"  {category}: score={score}, weight={weight}, contribution={weighted_contribution}")
    
    logger.info(f"Total weighted score: {total_weighted_score}")
    logger.info(f"Total weight: {total_weight}")
    
    # Avoid division by zero
    if total_weight == 0:
        logger.warning("Total weight is 0, returning score of 50")
        return 50
      # Calculate the average weighted score
    average_weighted_score = total_weighted_score / total_weight
    logger.info(f"Average weighted score: {average_weighted_score}")
    
    # Convert from -1.0 to 1.0 scale to 0 to 100 scale
    final_score = int((average_weighted_score + 1) * 50)
    logger.info(f"Final score (0-100): {final_score}")
    
    return final_score