# scripts/scorer.py (Simplified Version - No Confidence Score)

# ==============================================================================
# Part 1: Configuration
# ==============================================================================

# Default weights for the three-category model.
# These represent the relative importance of each category.
DEFAULT_WEIGHTS = {
    "material_composition": 4,
    "production_and_brand": 4,
    "circularity_and_end_of_life": 2,
}

# A single, standardized map for converting the LLM's ratings into numerical scores.
# The scale is from -1.0 (very bad) to 1.0 (very good).
RATING_SCORES = {
    'Excellent': 1.0,
    'Good': 0.6,
    'Neutral': 0.0,
    'Poor': -1.0,
    'Unknown': 0.0, # Treat 'Unknown' as a neutral 0.0 score.
}


# ==============================================================================
# Part 2: Scorer Functions
# ==============================================================================

def generate_sustainability_breakdown(analysis_json: dict) -> dict:
    """
    Extracts the new three-category breakdown structure from the LLM's analysis.
    This creates the rich object used for both display and calculation.

    Args:
        analysis_json: The full structured JSON object from the analyzer.

    Returns:
        A dictionary containing the detailed sustainability breakdown.
    """
    logger.info("=== SCORER: GENERATING SUSTAINABILITY BREAKDOWN ===")
    logger.info(f"Input analysis_json: {json.dumps(analysis_json, indent=2)}")
    
    breakdown = {}
    # The new analysis is nested under the 'sustainability_analysis' key
    sustainability_analysis = analysis_json.get('sustainability_analysis', {})
    
    # Iterate through our three main categories
    for category, details in sustainability_analysis.items():
        rating = details.get('rating', 'Unknown')
        breakdown[category] = {
            "value": rating,  # The qualitative rating (e.g., "Good")
            "score": RATING_SCORES.get(rating, 0.0), # The quantitative score
            "analysis": details.get('analysis', 'No analysis provided.')
        }
    return breakdown


def calculate_weighted_score(sustainability_breakdown: dict, user_weights: dict | None = None) -> int:
    """
    Calculates the final 0-100 score from the breakdown object and weights.
    This is a direct, unadjusted calculation.

    Args:
        sustainability_breakdown: The object generated by generate_sustainability_breakdown().
        user_weights: The user's personalized weights. If None, uses default weights.

    Returns:
        The final sustainability score, an integer between 0 and 100.
    """
    logger.info("=== SCORER: CALCULATING WEIGHTED SCORE ===")
    logger.info(f"Sustainability breakdown: {json.dumps(sustainability_breakdown, indent=2)}")
    logger.info(f"User weights: {user_weights}")
    
    # Use user-provided weights, or fall back to the defaults
    weights = user_weights or DEFAULT_WEIGHTS
    logger.info(f"Using weights: {weights}")
    
    total_weighted_score = 0
    total_weight = 0
    
    logger.info("Processing each category...")
    # Iterate through the breakdown object to calculate the total score
    for category, breakdown_details in sustainability_breakdown.items():
        # Get the normalized score (-1.0 to 1.0) for the category
        score = breakdown_details.get('score', 0.0)
        # Get the user's weight for that category
        weight = weights.get(category, 0)
        
        weighted_contribution = score * weight
        total_weighted_score += weighted_contribution
        total_weight += weight
        
        logger.info(f"  {category}: score={score}, weight={weight}, contribution={weighted_contribution}")
    
    logger.info(f"Total weighted score: {total_weighted_score}")
    logger.info(f"Total weight: {total_weight}")
    
    # Avoid division by zero
    if total_weight == 0:
        logger.warning("Total weight is 0, returning score of 50")
        return 50
      # Calculate the average weighted score
    average_weighted_score = total_weighted_score / total_weight
    logger.info(f"Average weighted score: {average_weighted_score}")
    
    # Convert from -1.0 to 1.0 scale to 0 to 100 scale
    final_score = int((average_weighted_score + 1) * 50)
    logger.info(f"Final score (0-100): {final_score}")
    
    return final_score